{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "from scipy.special import comb, perm\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from itertools import combinations\n",
    "from igraph import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = Path(fr'/Volumes/SP PHD U3/{year}_PTT_raw_data/covid-19/iii_not_merged')\n",
    "root_path_csv = Path(fr'/Volumes/SP PHD U3/{year}_PTT_raw_data/covid-19_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202105-type1-or2\n",
      "202106-type1-or2\n",
      "202102-type1-or2\n",
      "202101-type1-or2\n",
      "202103-type1-or2\n",
      "202104-type1-or2\n"
     ]
    }
   ],
   "source": [
    "for file in root_path.glob(f'*{year}*'):\n",
    "    if '._' not in file.stem:\n",
    "        print(file.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_time_gap(time_a, time_c):\n",
    "    time_format = '%Y/%m/%d %H:%M:%S'\n",
    "    timeString_a = time_a\n",
    "    struct_time_a = time.strptime(timeString_a, time_format)\n",
    "    time_stamp_a = int(time.mktime(struct_time_a))\n",
    "    timeString_c = time_c\n",
    "    struct_time_c = time.strptime(timeString_c, time_format)\n",
    "    time_stamp_c = int(time.mktime(struct_time_c))\n",
    "    time_gap = time_stamp_c - time_stamp_a\n",
    "    return time_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'202104'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.stem.split('-')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iii_202104_Gossiping_all'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'iii_'+file.stem.split('-')[0]+'_Gossiping_all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 轉CSV檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening 202106-type1-or2 at Sun Jul  4 18:02:22 2021\n",
      "saving 0 at Sun Jul  4 18:03:24 2021\n",
      "saving 10000 at Sun Jul  4 18:03:37 2021\n",
      "saving 20000 at Sun Jul  4 18:03:51 2021\n",
      "saving 30000 at Sun Jul  4 18:04:03 2021\n",
      "saving 40000 at Sun Jul  4 18:04:16 2021\n",
      "saving 50000 at Sun Jul  4 18:04:29 2021\n",
      "saving 60000 at Sun Jul  4 18:04:41 2021\n",
      "saving 70000 at Sun Jul  4 18:04:54 2021\n",
      "saving 80000 at Sun Jul  4 18:05:06 2021\n",
      "saving 81578 at Sun Jul  4 18:05:09 2021\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#清理後的留言時間為time，原始為post_time\n",
    "year = 2021\n",
    "\n",
    "for file in root_path.glob(f'*{year}06*'):\n",
    "    if '._' not in file.stem: #去除隱藏檔\n",
    "        print(f'opening {file.stem} at {time.ctime()}')\n",
    "        df_file_name = 'iii_'+file.stem.split('-')[0]+'_Gossiping_all'\n",
    "\n",
    "        author_reply = []  \n",
    "        header = ['id', 'time', 'title', 'author_id', \n",
    "                  'from_id', 'reaction', 'post_time', 'date_a', 'date_c'] \n",
    "        with open(root_path_csv / f'{df_file_name}.csv', 'w', newline='') as written_file:\n",
    "            writeCsv = csv.writer(written_file, delimiter=',')\n",
    "            writeCsv.writerow(header)\n",
    "\n",
    "        with open(file , 'r', encoding='utf8') as reader:\n",
    "            jf = json.loads(reader.read())\n",
    "\n",
    "            for idx, article in enumerate(jf):\n",
    "                if article['id'].startswith('Gossiping'):\n",
    "    \n",
    "                    for comment in article['comments']:\n",
    "                        time_a = article['time']\n",
    "                        time_c = comment['time']\n",
    "                        date_a = time_a.split(' ')[0]\n",
    "                        date_c = time_c.split(' ')[0]\n",
    "\n",
    "                        time_gap = count_time_gap(time_a, time_c)\n",
    "\n",
    "                        if 0 > time_gap >= -60 and type(article['id'])==str:                            \n",
    "                            author_reply.append((\n",
    "                                article['id'], #id\n",
    "                                time_a, #time\n",
    "                                article['title'], #title\n",
    "                                article['author_id'], #author_id\n",
    "                                comment['from_id'], \n",
    "                                comment['reaction'], \n",
    "                                time_a, #[post_time]\n",
    "                                date_a,\n",
    "                                date_c\n",
    "                            ))\n",
    "\n",
    "                        if time_gap >= 0 and type(article['id'])==str:                            \n",
    "                            author_reply.append((\n",
    "                                article['id'], #id\n",
    "                                time_a, #time\n",
    "                                article['title'], #title\n",
    "                                article['author_id'], #author_id\n",
    "                                comment['from_id'], \n",
    "                                comment['reaction'], \n",
    "                                time_c, #[post_time]\n",
    "                                date_a,\n",
    "                                date_c\n",
    "                            ))\n",
    "\n",
    "                if idx % 10000 == 0:\n",
    "                    print(f'saving {idx} at {time.ctime()}')\n",
    "                    with open(root_path_csv/f'{df_file_name}.csv', 'a', newline='') as written_file:\n",
    "                        writeCsv = csv.writer(written_file, delimiter=',')\n",
    "                        writeCsv.writerows(author_reply)                       \n",
    "                    author_reply = []      \n",
    "\n",
    "            if idx % 10000 != 0:\n",
    "                print(f'saving {idx} at {time.ctime()}')\n",
    "                with open(root_path_csv/f'{df_file_name}.csv', 'a', newline='') as written_file:\n",
    "                    writeCsv = csv.writer(written_file, delimiter=',')\n",
    "                    writeCsv.writerows(author_reply)   \n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 標題分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_filter():\n",
    "    for rows in title_df.itertuples():        \n",
    "            \n",
    "        if 'Re:' in rows.title:\n",
    "            title_df.loc[rows.Index, 'category'] = 'Re'\n",
    "            \n",
    "        else:\n",
    "            if '[爆卦]' in rows.title:\n",
    "                title_df.loc[rows.Index, 'category'] = '爆卦'\n",
    "            elif '[問卦]' in rows.title:\n",
    "                title_df.loc[rows.Index, 'category'] = '問卦'\n",
    "            elif '[新聞]' in rows.title:\n",
    "                title_df.loc[rows.Index, 'category'] = '新聞'\n",
    "            else:\n",
    "                title_df.loc[rows.Index, 'category'] = 'others'\n",
    "        \n",
    "    return title_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat = ['[請問]', '[爆卦]', '[問卦]', '[新聞]', '[舊聞]', '[問題]', '[分享]', '[活動]', '[參選]', \n",
    "#        '[問話]', '[廢文]', '[心得]', '[協尋]', '[公告]', '[尋人]', '[地震]', '[請益]', '[無]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening iii_202106_Gossiping_all at Sun Jul  4 18:06:00 2021\n",
      "(4517417, 9)\n",
      "saving iii_202106_Gossiping_all at Sun Jul  4 18:06:18 2021\n",
      "(4517417, 10)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for file in root_path_csv.glob(f'*{year}06*Gossiping_all*'):\n",
    "    if '._' not in file.stem:\n",
    "        print(f'opening {file.stem} at {time.ctime()}')     \n",
    "        raw_data = pd.read_csv(file)\n",
    "        print(raw_data.shape)\n",
    "        raw_data = raw_data.dropna(axis=0, how='any')\n",
    "        \n",
    "        title_df = raw_data[['id', 'title']].drop_duplicates()\n",
    "        title_df = cat_filter()          \n",
    "        new_data = title_df.merge(raw_data)\n",
    "        \n",
    "        print(f'saving {file.stem} at {time.ctime()}')\n",
    "        print(new_data.shape)\n",
    "        new_data.to_csv(root_path_csv/f'{file.stem}.csv', index=False)\n",
    "\n",
    "        print('='*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# covid-19相關文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_filter(word_topic, topic):\n",
    "    for rows in title_df.itertuples():        \n",
    "        for word in word_topic:\n",
    "            \n",
    "            if word in rows.title:\n",
    "                title_df.loc[rows.Index, topic] = 1\n",
    "    \n",
    "    return title_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_covid = ['變種', '四級', '疾管家', '封城', '復星', '萬華', '醫院', '方艙', '院內', '陽性率', '篩檢', '復必泰',\n",
    "              '超前部署', '醫護', '輕症', 'J&J', '抗疫', '茶室', '衛福部', '指揮中心', '確診', '莫德納', '南送', \n",
    "              '輝瑞', '三級', 'PCR', '境外', '重症', '肺炎', '採檢', 'BioNTech', '高端', 'Moderna', '國藥', \n",
    "              '諾富特', '疫情', '快篩', '校正回歸', '防疫', '疫調', '偽陰', '機師', '實聯制', '本土', '傳播鏈', '疫苗',\n",
    "              'BNT', '超前', 'moderna', '科興', '陳時中', '聯亞', '3+11', '病毒株', '口罩', '廣篩', '國產疫苗', \n",
    "              '染疫', '隔離', '普篩', '實名制', 'AZ', 'Ct值', '感染', '群聚', '偽陽', '人與人', '社區', '嬌生']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vaccine = ['疫苗', '國產疫苗', '聯亞','高端',\n",
    "                'AZ', 'Moderna', 'moderna', '莫德納', '嬌生', 'J&J', 'BNT', 'BioNTech', '復必泰', \n",
    "                '科興', '國藥', '復星',\n",
    "                '輝瑞']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cecc = ['衛福部', '指揮中心', '陳時中', '疫調', '校正回歸', '疾管家', '實聯制', '實名制',  \n",
    "             '超前', '超前部署', '南送']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening iii_202106_Gossiping_all at Sun Jul  4 18:09:10 2021\n",
      "num of article_all: 80833\n",
      "num of article_covid: 16153\n",
      "saving iii_202106_Gossiping_all at Sun Jul  4 18:09:26 2021\n",
      "====================================================================================================\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# data_range = 'covid'\n",
    "# word_lst = word_covid\n",
    "data_range = 'vaccine'\n",
    "word_lst = word_vaccine\n",
    "# data_range = 'CECC'\n",
    "# word_lst = word_cecc\n",
    "\n",
    "for file in root_path_csv.glob(f'*{year}06*Gossiping_all*'):\n",
    "    if '._' not in file.stem: #去除隱藏檔\n",
    "        print(f'opening {file.stem} at {time.ctime()}')\n",
    "        \n",
    "        raw_data = pd.read_csv(file)\n",
    "\n",
    "        title_df = raw_data[['id', 'title']].drop_duplicates()\n",
    "        print(f'num of article_all: {len(set(raw_data.id))}')\n",
    "        \n",
    "        df_file_name = str(file.stem).replace('all', data_range)\n",
    "        title_df = topic_filter(word_lst, data_range)\n",
    "        covid_data = title_df[title_df[data_range] == 1]\n",
    "#         print(len(set(covid_data.id)))\n",
    "        \n",
    "        new_data = covid_data.merge(raw_data, how='left')\n",
    "        print(f'num of article_covid: {len(set(new_data.id))}')\n",
    "        \n",
    "        print(f'saving {file.stem} at {time.ctime()}')\n",
    "        new_data.to_csv(root_path_csv/f'{df_file_name}.csv', index=False)\n",
    "        \n",
    "        print('='*100)\n",
    "                      \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 母體計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iii_202102_Gossiping_covid Wed Nov 10 20:11:56 2021\n",
      "iii_202101_Gossiping_covid Wed Nov 10 20:11:57 2021\n",
      "iii_202103_Gossiping_covid Wed Nov 10 20:11:57 2021\n",
      "iii_202104_Gossiping_covid Wed Nov 10 20:11:58 2021\n",
      "iii_202105_Gossiping_covid Wed Nov 10 20:11:58 2021\n",
      "iii_202106_Gossiping_covid Wed Nov 10 20:12:02 2021\n",
      "done\n",
      "4196595\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "data_range = 'covid'\n",
    "num_comment = 0\n",
    "\n",
    "for file in root_path_csv.glob(f'*{year}*Gossiping*{data_range}*'):\n",
    "    if '._' not in file.stem:\n",
    "        print(file.stem, time.ctime())\n",
    "        month_df = pd.read_csv(file)\n",
    "        num_comment = num_comment + len(month_df)\n",
    "        \n",
    "        month_need_df = month_df[['id', 'author_id', 'from_id']]\n",
    "            \n",
    "        df = pd.concat([df, month_need_df])\n",
    "        \n",
    "print('done') \n",
    "print(num_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25857768057774677"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4196595/16229533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16229533"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369545"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9204"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['author_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78527"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['from_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172183"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['from_id']).union(set(df['author_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
